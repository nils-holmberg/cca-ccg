{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "e19a0856-d3b4-54b6-bdc2-01053b99a2c2",
        "openai_ephemeral_user_id": "d3846df0-f8c4-59ed-9a63-7178ba7b3db3",
        "openai_subdivision1_iso_code": "SE-M"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "noteable": {
      "last_transaction_id": "c2403571-db06-47ff-971a-d369feeba8a5"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "45d09c3f-8e35-4092-976b-18e0388831a1",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    },
    {
      "id": "9afbae7c-e78c-4d78-ab2a-94fa9a4c42a1",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "502ee840-bd50-45c6-a74a-d83f27738875"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:01:03.960044+00:00",
          "start_time": "2023-08-18T11:59:06.137229+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install git+https://github.com/openai/whisper.git",
      "outputs": []
    },
    {
      "id": "23118b88-e0e8-4a11-9147-124b71953fd8",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "cb0f9c21-8b58-4e20-98bb-ba16a7c82cf5"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:04:49.910754+00:00",
          "start_time": "2023-08-18T12:04:46.824370+00:00"
        }
      },
      "execution_count": null,
      "source": "import torch\nfrom whisper import WhisperASR\n\n# Load the Whisper ASR model\nmodel = WhisperASR()\n\n# Load the audio file\naudio_path = 'res/en-clip.wav'\naudio = torch.from_numpy(model.load_audio(audio_path)).unsqueeze(0)\n\n# Transcribe the audio\ntranscription = model.transcribe(audio)\ntranscription",
      "outputs": []
    },
    {
      "id": "f8ed2d5e-73f7-4338-9050-3aa50fb49295",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ba70d790-5909-4560-b9b8-714c35cde954"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:05:09.335873+00:00",
          "start_time": "2023-08-18T12:05:09.175011+00:00"
        }
      },
      "execution_count": null,
      "source": "import torch\nimport whisper\n\n# Checking the available attributes in the whisper package to identify the correct module for ASR\ndir(whisper)",
      "outputs": []
    }
  ]
}