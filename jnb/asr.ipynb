{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "e19a0856-d3b4-54b6-bdc2-01053b99a2c2",
        "openai_ephemeral_user_id": "d3846df0-f8c4-59ed-9a63-7178ba7b3db3",
        "openai_subdivision1_iso_code": "SE-M"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "noteable": {
      "last_transaction_id": "1dbb1feb-62e4-4fa5-98dd-1806264cde5f"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "9afbae7c-e78c-4d78-ab2a-94fa9a4c42a1",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "3c1247d9-ef6e-40de-9b01-a78b227ad449"
        },
        "ExecuteTime": null
      },
      "execution_count": null,
      "source": "!pip install -q git+https://github.com/openai/whisper.git",
      "outputs": []
    },
    {
      "id": "23118b88-e0e8-4a11-9147-124b71953fd8",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "cb0f9c21-8b58-4e20-98bb-ba16a7c82cf5"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:04:49.910754+00:00",
          "start_time": "2023-08-18T12:04:46.824370+00:00"
        }
      },
      "execution_count": null,
      "source": "import torch\nfrom whisper import WhisperASR\n\n# Load the Whisper ASR model\nmodel = WhisperASR()\n\n# Load the audio file\naudio_path = 'res/en-clip.wav'\naudio = torch.from_numpy(model.load_audio(audio_path)).unsqueeze(0)\n\n# Transcribe the audio\ntranscription = model.transcribe(audio)\ntranscription",
      "outputs": []
    },
    {
      "id": "f8ed2d5e-73f7-4338-9050-3aa50fb49295",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ba70d790-5909-4560-b9b8-714c35cde954"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:05:09.335873+00:00",
          "start_time": "2023-08-18T12:05:09.175011+00:00"
        }
      },
      "execution_count": null,
      "source": "import torch\nimport whisper\n\n# Checking the available attributes in the whisper package to identify the correct module for ASR\ndir(whisper)",
      "outputs": []
    },
    {
      "id": "fd839b8f-cd32-4311-8d12-acfc14b62e12",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "49afbcfa-9f7a-4287-bf88-b6481919038e"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:05:29.243199+00:00",
          "start_time": "2023-08-18T12:05:29.062848+00:00"
        }
      },
      "execution_count": null,
      "source": "from whisper import Whisper\n\n# Load the Whisper ASR model\nmodel = Whisper()\n\n# Transcribe the audio\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "4b2fc5c3-57d6-4956-bfae-eed41c53c96c",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4180d021-8e5a-4b9d-9570-ce2e42e54447"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:06:17.062099+00:00",
          "start_time": "2023-08-18T12:06:16.902282+00:00"
        }
      },
      "execution_count": null,
      "source": "# Checking available pre-trained models in the whisper package\nwhisper.available_models()",
      "outputs": []
    },
    {
      "id": "88444aa8-2a5f-4142-90f1-5ec18608ba7b",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "49e21afb-3c3e-473d-84ae-5be43007cd94"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:06:43.033422+00:00",
          "start_time": "2023-08-18T12:06:42.803605+00:00"
        }
      },
      "execution_count": null,
      "source": "# Load the 'base.en' model from the available models\nmodel = whisper.Whisper('base.en')\n\n# Transcribe the audio\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "d0f41937-4f69-4810-999d-409a2baa5a2b",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "6f701249-23d9-4fc1-886a-1127983089b7"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:07:10.072328+00:00",
          "start_time": "2023-08-18T12:07:09.891256+00:00"
        }
      },
      "execution_count": null,
      "source": "# Load the 'base.en' model dimensions and then initialize the Whisper model with those dimensions\ndims = whisper.ModelDimensions('base.en')\nmodel = whisper.Whisper(dims)\n\n# Transcribe the audio\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "37da3764-3ba4-42be-a32e-07eb87164eae",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f02611df-cebd-4b19-9026-701b433b854f"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:09:27.311952+00:00",
          "start_time": "2023-08-18T12:09:15.461816+00:00"
        }
      },
      "execution_count": null,
      "source": "import whisper\n\n# Load the 'base' model using the provided code\nmodel = whisper.load_model(\"base\")\n\n# Transcribe the audio\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "9139f33f-e680-4887-8d29-10d359f25acf",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "1cb51d23-929b-4827-a814-1000c95fda78"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:11:55.872643+00:00",
          "start_time": "2023-08-18T12:11:54.920430+00:00"
        }
      },
      "execution_count": null,
      "source": "# Transcribe the English audio file in the 'res' folder using the loaded 'base' model\naudio_path = 'res/en-clip.wav'\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "1f858d26-2b7f-42e8-bc05-35f4fff8b7a7",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4da77b43-eb0b-4071-8e15-ebe01b639dd2"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:12:34.620070+00:00",
          "start_time": "2023-08-18T12:12:34.237835+00:00"
        }
      },
      "execution_count": null,
      "source": "# Transcribe the English audio file using the loaded 'base' model\naudio_path = './res/en-clip.wav'\ntranscription = model.transcribe(audio_path)\ntranscription",
      "outputs": []
    },
    {
      "id": "12cf1c65-8954-4c63-9739-b431734d7ed5",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "089391e7-9ab1-4aa4-b0b2-01762caa98c0"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:13:01.174683+00:00",
          "start_time": "2023-08-18T12:13:00.993083+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\n\n# Verify the current working directory and list files in 'res' folder\ncurrent_directory = os.getcwd()\nres_files = os.listdir('./res')\ncurrent_directory, res_files",
      "outputs": []
    },
    {
      "id": "1c2d0aa5-634a-47db-a3a9-66a782a2c688",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f6421816-122c-481d-a78f-98aa1e5a25ad"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T12:13:25.272614+00:00",
          "start_time": "2023-08-18T12:13:25.036489+00:00"
        }
      },
      "execution_count": null,
      "source": "import IPython.display as ipd\n\n# Attempt to load and display the audio file to verify its accessibility\nipd.Audio('res/en-clip.wav')",
      "outputs": []
    }
  ]
}