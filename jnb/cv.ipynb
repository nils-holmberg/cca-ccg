{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "0fa2d118-f158-5666-9a41-9a69584e8a19",
        "openai_ephemeral_user_id": "a8083c3c-ec00-56b4-9183-4432a0b27547",
        "openai_subdivision1_iso_code": "SE-M"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "noteable": {
      "last_transaction_id": "5471f2f0-7179-4b1b-95c0-52fd5d6d285f"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "aebbaa31-c3f4-4f2f-970d-dd554b0b3561",
      "cell_type": "markdown",
      "source": "This cell saves the annotated image with bounding boxes, labels, and confidence scores to the Noteable project. The path to the saved image is then displayed.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "fb3f6c2f-e426-4c16-9f7f-e45b83f8c364",
      "cell_type": "markdown",
      "source": "This cell uses the OpenCV library to draw rectangles around the detected objects in the image. Each rectangle is accompanied by a label indicating the type of object and its detection confidence score. The annotated image is then displayed.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "59f8cd89-90a0-4c3b-b9ae-9c75331ea05c",
      "cell_type": "markdown",
      "source": "This cell extracts the labels, pixel locations, and confidence scores of the detected objects and stores them in a pandas dataframe. The dataframe is then displayed, showing the label of each detected object, its bounding box coordinates, and the confidence score of the detection.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "aba703f3-049d-44a5-a7c6-a31102d6c2c0",
      "cell_type": "markdown",
      "source": "This cell installs the `opencv-python` package, which is a library for computer vision tasks. The code then imports necessary modules and reads an image from the specified path. The image's color channels are converted from BGR (Blue, Green, Red) to RGB (Red, Green, Blue) format. Finally, the image is displayed using the `matplotlib` library.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "5b29c224-2138-4b49-a287-602104590c5d",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f5962be5-55f6-4f22-bb9c-6b913d19f930"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:05:03.701121+00:00",
          "start_time": "2023-08-06T15:04:57.232931+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install -q opencv-python\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Read the image using OpenCV\nimage_path = 'fig/04Ge3YMUnWc.mp4-00049.jpg'\nimage = cv2.imread(image_path)\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Display the image using matplotlib\nplt.imshow(image_rgb)\nplt.axis('off')\nplt.show()",
      "outputs": []
    },
    {
      "id": "5bd870c3-f5d1-4446-9cc8-8a0cb24cba32",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "550bbddd-2849-47a1-b231-257aca942e13"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:05:10.429012+00:00",
          "start_time": "2023-08-06T15:05:04.259845+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install -q transformers timm torch",
      "outputs": []
    },
    {
      "id": "ca4bc4c9-35ed-49ad-bf6c-7a7f3c917cdb",
      "cell_type": "markdown",
      "source": "This cell installs the `transformers`, `timm`, and `torch` packages. These libraries are essential for working with transformer models and deep learning in Python.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "7aa1d795-548f-4b93-abef-3ba42e05ccff",
      "cell_type": "markdown",
      "source": "This cell imports the `DetrImageProcessor` and `DetrForObjectDetection` classes from the `transformers` library, as well as the `torch` library. These are used for object detection tasks using the DETR (DEtection TRansformer) model.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "07c6bd23-53c3-41ef-8f77-6c6e60d75c1b",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a8ac78ea-03f7-4aa6-9a3a-10e2fa05340f"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:05:10.599111+00:00",
          "start_time": "2023-08-06T15:05:10.437816+00:00"
        }
      },
      "execution_count": null,
      "source": "from transformers import DetrImageProcessor, DetrForObjectDetection\nimport torch",
      "outputs": []
    },
    {
      "id": "0b43254e-e033-4907-8eee-ff036eecf231",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "883f1f84-50ca-4540-986a-5fe3f86e0dee"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:05:10.792109+00:00",
          "start_time": "2023-08-06T15:05:10.635735+00:00"
        }
      },
      "execution_count": null,
      "source": "from PIL import Image\nimport requests",
      "outputs": []
    },
    {
      "id": "cc143ff8-14fd-426a-a75c-8d6df3b58182",
      "cell_type": "markdown",
      "source": "This cell imports the `Image` class from the `PIL` library and the `requests` module. The `Image` class is used for opening, manipulating, and saving different image file formats, while the `requests` module allows for making HTTP requests.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "794a8cbf-e432-4b5d-95a7-95cf241ed880",
      "cell_type": "markdown",
      "source": "This cell fetches an image from a specified URL and opens it using the `Image` class from the `PIL` library. It then initializes the DETR image processor and model for object detection. The image is processed and passed to the model to detect objects. The detected objects, their locations (bounding boxes), and confidence scores are then printed.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "cb0ffa33-3811-4c0f-aa4e-ef58cb6ca0c0",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "fac9266b-da1d-482d-aca8-2fd79cacb11f"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:05:29.598303+00:00",
          "start_time": "2023-08-06T15:05:10.829060+00:00"
        }
      },
      "execution_count": null,
      "source": "\n\n\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\nurl = \"https://raw.githubusercontent.com/nils-holmberg/scom-dm/main/img/04Ge3YMUnWc.mp4-00049.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\nprocessor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\nmodel = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n\ninputs = processor(images=image, return_tensors=\"pt\")\noutputs = model(**inputs)\n\n# convert outputs (bounding boxes and class logits) to COCO API\n# let's only keep detections with score > 0.9\ntarget_sizes = torch.tensor([image.size[::-1]])\nresults = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n\nfor score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n    box = [round(i, 2) for i in box.tolist()]\n    print(\n            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n            f\"{round(score.item(), 3)} at location {box}\"\n    )",
      "outputs": []
    },
    {
      "id": "8434a73e-7042-40fc-845d-0d64f37190b6",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "cf757c3e-f1ab-460f-b184-3c6108eab74c"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:08:30.351527+00:00",
          "start_time": "2023-08-06T15:08:30.121088+00:00"
        },
        "datalink": {
          "8064fa35-6918-4b30-a474-b718ccac7af4": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 3,
              "orig_num_rows": 6,
              "orig_size_bytes": 192,
              "truncated_num_cols": 3,
              "truncated_num_rows": 6,
              "truncated_size_bytes": 192,
              "truncated_string_columns": []
            },
            "display_id": "8064fa35-6918-4b30-a474-b718ccac7af4",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-08-06T15:08:30.192630",
            "user_variable_name": "df",
            "variable_name": "df"
          }
        }
      },
      "execution_count": null,
      "source": "import pandas as pd\n\n# Extracting object detection labels and pixel locations\ndata = []\nfor score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n    box = [round(i, 2) for i in box.tolist()]\n    data.append([model.config.id2label[label.item()], box, round(score.item(), 3)])\n\n# Creating a pandas dataframe\ndf = pd.DataFrame(data, columns=['Label', 'Pixel Location (x1, y1, x2, y2)', 'Confidence'])\ndf",
      "outputs": []
    },
    {
      "id": "10730da3-3df5-4889-b0f4-e6c5dbe1514c",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "27280136-f0a0-403d-9391-620ef8d66458"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:10:50.060802+00:00",
          "start_time": "2023-08-06T15:10:49.472350+00:00"
        }
      },
      "execution_count": null,
      "source": "# Draw rectangles, labels, and confidence on the image using OpenCV\nfor _, row in df.iterrows():\n    label, box, confidence = row['Label'], row['Pixel Location (x1, y1, x2, y2)'], row['Confidence']\n    x1, y1, x2, y2 = box\n    cv2.rectangle(image_rgb, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n    cv2.putText(image_rgb, f'{label}: {confidence:.2f}',\n                (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\n# Display the image with bounding boxes, labels, and confidence\nplt.imshow(image_rgb)\nplt.axis('off')\nplt.show()",
      "outputs": []
    },
    {
      "id": "9135c0f2-c886-41a9-af8c-cdfb2d05f4a4",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "3bf528fa-9fd7-4590-ad85-9fde485a6cb1"
        },
        "ExecuteTime": {
          "end_time": "2023-08-06T15:13:03.534839+00:00",
          "start_time": "2023-08-06T15:13:03.363134+00:00"
        }
      },
      "execution_count": null,
      "source": "# Save the annotated image to the Noteable project\noutput_image_path = 'fig/Annotated_Image.jpg'\ncv2.imwrite(output_image_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\noutput_image_path",
      "outputs": []
    }
  ]
}